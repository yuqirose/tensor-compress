{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM cell \n",
    "$$ i, j, f, o = Wx + Uh + b \\\\\n",
    "   [i,j,f,o] = [W,U,1][x,h,b]^\\top$$\n",
    "  i = input_gate, j = new_input, f = forget_gate, o = output_gate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "# %load unit_test.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.python.ops import embedding_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.util import nest\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "import tensornet\n",
    "from tensorflow.python.ops.rnn_cell import *\n",
    "from TensorBasicLSTMCell import TensorBasicLSTMCell\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(1)\n",
    "    # the size of the hidden state for the lstm (notice the lstm uses 2x of this amount so actually lstm will have state of size 2)\n",
    "    size = 12\n",
    "    # 2 different sequences total\n",
    "    batch_size= 2\n",
    "    # the maximum steps for both sequences is 10\n",
    "    n_steps = 10\n",
    "    # each element of the sequence has dimension of 5\n",
    "    seq_width = 2\n",
    "\n",
    "    # the first input is to be stopped at 4 steps, the second at 6 steps\n",
    "    e_stop = np.array([4,6])\n",
    "    \n",
    "    # factorize the inp\n",
    "    inp_modes = {}\n",
    "    out_modes = {}\n",
    "    mat_ranks = {}\n",
    "    # input weights\n",
    "#     inp_modes['x'] = np.array([1, 2, 1, 1], dtype='int32') # product as seq_width\n",
    "#     out_modes['x'] = np.array([1, 4, 3, 1], dtype='int32') # product as num_units (size)\n",
    "    mat_ranks['x'] = 2\n",
    "    #mat_ranks['x'] = np.array([1, 2, 2, 2, 1], dtype='int32')\n",
    "    # hidden state weights\n",
    "#     inp_modes['h'] = np.array([1, 4, 3, 1], dtype='int32') # seq_width\n",
    "#     out_modes['h'] = np.array([1, 4, 3, 1], dtype='int32') # 4 * num_units\n",
    "    mat_ranks['h'] = 2\n",
    "\n",
    "    #mat_ranks['h'] = np.array([1, 2, 2, 2, 1], dtype='int32') \n",
    "    \n",
    "    \n",
    "    initializer = tf.random_uniform_initializer(-1,1)\n",
    "\n",
    "    # the sequences, has n steps of maximum size\n",
    "    seq_input = tf.placeholder(tf.float32, [n_steps, batch_size, seq_width], name=\"placeholder/seqs\")\n",
    "    # what timesteps we want to stop at, notice it's different for each batch hence dimension of [batch]\n",
    "    early_stop = tf.placeholder(tf.int32, [batch_size], name=\"placeholder/stops\" )\n",
    "\n",
    "    # inputs for rnn needs to be a list, each item being a timestep.\n",
    "    # we need to split our input into each timestep, and reshape it because split keeps dims by default\n",
    "    # input = [n_steps, batch_size, seq_width]\n",
    "    inputs = [tf.reshape(i, (batch_size, seq_width)) for i in tf.split(0, n_steps, seq_input)]\n",
    "    \n",
    "    \"\"\"Shape checker\"\"\"\n",
    "#     init = tf.initialize_all_variables()\n",
    "#     sess = tf.InteractiveSession()\n",
    "#     sess.run(init)\n",
    "#     print(sess.run(tf.shape(inputs), feed_dict = {seq_input: np.ones((n_steps, batch_size, seq_width)) }))\n",
    "#     sess.close()\n",
    "    \n",
    "    cell = TensorBasicLSTMCell(size, mat_ranks=mat_ranks, initializer=initializer)        \n",
    "        \n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    # ========= This is the most important part ==========\n",
    "    # output will be of length 4 and 6\n",
    "    # the state is the final state at termination (stopped at step 4 and 6)\n",
    "    outputs, state = tf.nn.rnn(cell, inputs, initial_state=initial_state, sequence_length=early_stop)\n",
    "\n",
    "    # usual crap\n",
    "    iop = tf.initialize_all_variables()\n",
    "    session = tf.Session()\n",
    "    session.run(iop)\n",
    "    feed = {early_stop:e_stop, seq_input:np.random.rand(n_steps, batch_size, seq_width).astype('float32')}\n",
    "\n",
    "    print(\"outputs, should be 2 things one of length 4 and other of 6\")\n",
    "    outs = session.run(outputs, feed_dict=feed)\n",
    "    for xx in outs:\n",
    "        print(xx)\n",
    "\n",
    "    print(\"states, 2 things total both of size 2, which is the size of the hidden state\")\n",
    "    st = session.run(state, feed_dict=feed)\n",
    "    print(st)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
